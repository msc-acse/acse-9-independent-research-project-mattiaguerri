##### VERSION CONTROL #####

- MachineWorkFlow_00 ------------ Original Code.
- MachineWorkFlow_01 ------------ Copy of MachineWorkFlow_00.
                                  Added Normalization + Standardization + Batch Normalization.
- MachineWorkFlow_02 ------------ Copy of MachineWorkFlow_00. Added various architectures. They are in the file networks.py.
                                  Changed how the architecture is defined. It is here defined in the parameters.ini.
                                  Try to not load the whole data in the GPU, but only the batch.
                                  Apparently the code was already loading up only the single batch.
                                  The model is now worked on parallel on multiple GPUs. The model is copied on all of them,
                                  the batch is instead split among them.
                                  Added Normalization + Standardization + Batch Normalization.
                                  Adding the U-Net.
- MachineWorkFlow_03 ------------ Start form scratch. Try to join the code from the mini-project with the code from CGG.
- MachineWorkFlowDev00 ---------- Copy of MachineWorkFlow_00
                                  While trying to add U-Net I messed up MachineWorkFlow_02 irrimediabely. 
                                  I re-start from scratch.
- MachineDev00 ------------------ Copy of /programming/aclowes/for_production/seismic2seismic (08-07-2019).
- Machine1507Dev00 -------------- Copy of the pipeline from /tpanew/shou/seismic2seismic
                                  The email about this pipeline was received 15/07/2019.
                                  Working to add UNet with downsampling on only one direction.
- MachineRunBaseLine ------------ Baseline model, trained on full preduction data.
- MachineRunBaseLineFastTrack --- Baseline model, trained on fast track data.
- MachineRunUNet07 -------------- UNet07 trained on full production data.
- MachineRunUNet07Epo300 -------- Re-starting the training from model 167 of the folder MachineRunUNet07.
                                  Metrics are in folder 1.
                                  Minimum reached for model 59.
                                  Training stopped after epoch 141 because i was overfitting.
- MachineRunUNet07Epo300Tra ----- Re-starting training from model 59 of MachineRunUNet07Epo300.
                                  The training uses the L1 loss function.
                                  Regularization is set to 1e-3.
                                  Metrics are in folder 2.
- MachineRunUNet07FasTraDegTra -- Trained completed.
                                  Re-training with transfer learning using another loss function.
                                  Trained on fast track deghosted dataset.
- MachineDev01 ------------------ Metrics 1 is for unet07. Training finished.
                                  Metrics 2 is for unet07bn. Training finished.
                                  Metrics 3 is for unet07var. Traininf finished.
- MachineDev02 ------------------ Test weight decay. Training finished.
                                  










#######################################################################
Questions
- When i do the standardization, do i have to compute the parameters (mean and std) using only the training set? Or using
  training set + validation set together???
- In the UNet, do i need to activate the result of the transposed convolution?
- In the UNet with batch normalization, should i batch norm the output of the transpose convolution?
#######################################################################





#######################################################################
Useful Links
- Review Semantic Segmentation Algorithms: https://medium.com/@arthur_ouaknine/review-of-deep-learning-algorithms-for-image-semantic-segmentation-509a600f7b57
- Batch Normalization: https://machinelearningmastery.com/batch-normalization-for-training-of-deep-neural-networks/
- FCN paper: https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf
- Blog article about VGG16: https://neurohive.io/en/popular-networks/vgg16/
- VGG16 Article: https://arxiv.org/abs/1409.1556
- Residual Network Paper: https://arxiv.org/pdf/1512.03385.pdf
- Autonomous cars economic impact: https://www.theverge.com/2017/6/1/15725516/intel-7-trillion-dollar-self-driving-autonomous-cars
- U-Net implementation: https://www.kaggle.com/witwitchayakarn/u-net-with-pytorch/notebook
- Custom Kernel https://discuss.pytorch.org/t/custom-convolutional-kernel/30716
#######################################################################





##### TESTS ###########################################################
This is all using the first csv files for training, validation and inference.
Epochs (E) = 200 unless specified.
Batch Size (BS) = 4 unless specified.

- output_00, CGG8, .............[128, 64, 64, 64, 64, 32, 16], ST 9:20, ET 00:11 (+1),  TL 1.7864690691976050, VL 3.3999928074914054
- output_01, CGG8NSBN,     ST 19:00, ET 10:15(+1), .................................... TL 1.5759501973517627, VL 3.1531237524908944
- output_02, CGG12, ................................................................... TL 1.6948972091653180, VL 3.2641788173366235
- output_03, CGG12BN,      ST 10:50, ET 19.15(+1), .................................... TL 1.5045548051663267, VL 3.1070716767697720
- output_04, CGG15, 100 E, ST 11:00, ET 01:02(+1), .................................... TL 1.7760124316020889, VL 3.3942056024396740
- output_05, CGG15NSBN,    ST 10:30, ET 23:30, ........................................ TL 1.1322007296847650, VL 3.2677156538576693

- output_UNet_01, .............. [64, 128, 256, 512, 1024]...............TL 0.8330796942824409, VL 2.8687951886976086
- output_UNet_02, .............. [64, 128, 256, 512, 1024, 1024, 1024]...TL 0.5091864192972377, VL 2.8062365570583860
- output_UNet_04, .............. [64, 128, 256, 512, 1024, 2048].........TL 0.6378958375275541, VL 2.9634264127628223
- output_UNet_05, BS=2 ......... [64, 128, 256, 512, 1024, 2048, 4096]...TL 0.6041997219699851, VL 2.6939100300943530
- output_UNet_06, .............. [64, 128, 256, 512, 1024], carry,.......TL 0.8556496554356313, VL 2.9340661731926170
- output_UNetRes_01,............ [64, 128, 256, 512, 1024],..............TL 0.5897464164936083, VL 2.9630362955299585 test sopped early
#######################################################################


#######################################################################
source /cgv/geovation/2-db9/rel/python/venv/3.6/ml.003/bin/activate.csh
setenv PATH /cgv/geovation/2-db9/rel/bin:$PATH
setenv LD_LIBRARY_PATH /programming/imikhale/local/cuda/cuda-9.0/lib64/:/programming/imikhale/local/cuda/cudnn-9.0-v7.4/lib64/

cd /flat1/3dwoswaz/guerri/

#######################################################################
#######################################################################
source /programming/imikhale/local/bin/venv_db9/bin/activate.csh
tensorboard --logdir='./output/' --port=6006

#######################################################################


##### TESTS ###########################################################
MachineRunBaseLine
MachineRunBaseLineFastTrack
MachineRunUnet04,          [64, 128, 256, 512, 1024, 2048]
MachineRunUnet07,          [64, 96, 144, 216, 324, 486, 729, 1094, 1641], 2X 1080, BS 4
MachineRunUnet07Transfer,  [64, 96, 144, 216, 324, 486, 729, 1094, 1641], 2X 1080, BS 4
MachineRunUnet07FasTraDeg, [64, 96, 144, 216, 324, 486, 729, 1094, 1641], 2X 1080, BS 4



MachineRunUNet07Epo300Tra, training on redg99203
Machine1507RunUNet07Hor, training on redg99203
Machine1507RunUNet07Hor01, training on redg37022
MachineRunUNet07Deg, training on redg37024
MachineRunUNet07, I wanna train again, training on redg37024
MachineRunUNet07BigBat, bartch size = 12, training on redg36024
########################################################################











